{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing python-arango...\n",
      "Requirement already satisfied: python-arango in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (8.1.6)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (from python-arango) (2.3.0)\n",
      "Requirement already satisfied: requests in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (from python-arango) (2.32.3)\n",
      "Requirement already satisfied: requests_toolbelt in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (from python-arango) (1.0.0)\n",
      "Requirement already satisfied: PyJWT in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (from python-arango) (2.10.1)\n",
      "Requirement already satisfied: setuptools>=42 in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (from python-arango) (75.8.2)\n",
      "Requirement already satisfied: importlib_metadata>=4.7.1 in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (from python-arango) (8.6.1)\n",
      "Requirement already satisfied: packaging>=23.1 in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (from python-arango) (24.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (from importlib_metadata>=4.7.1->python-arango) (3.21.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (from requests->python-arango) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (from requests->python-arango) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (from requests->python-arango) (2025.1.31)\n",
      "✅ Successfully installed python-arango\n",
      "Installing networkx>=3.0...\n",
      "Requirement already satisfied: networkx>=3.0 in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (3.4)\n",
      "✅ Successfully installed networkx>=3.0\n",
      "✅ pandas is already installed\n",
      "✅ tqdm is already installed\n",
      "✅ langchain-cohere is already installed\n",
      "✅ langchain-community is already installed\n",
      "✅ langchain is already installed\n",
      "✅ matplotlib is already installed\n",
      "Installing python-louvain...\n",
      "Requirement already satisfied: python-louvain in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (0.16)\n",
      "Requirement already satisfied: networkx in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (from python-louvain) (3.4)\n",
      "Requirement already satisfied: numpy in /home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages (from python-louvain) (1.26.4)\n",
      "✅ Successfully installed python-louvain\n",
      "✅ requests is already installed\n",
      "✅ httpx-sse is already installed\n",
      "✅ openai is already installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ gradio is already installed\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: Install Required Packages ---\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installs a package using pip, handling potential errors.\"\"\"\n",
    "    try:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✅ Successfully installed {package}\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Failed to install {package}: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Unexpected error installing {package}: {e}\")\n",
    "        return False\n",
    "\n",
    "required_packages = [\n",
    "    \"python-arango\",\n",
    "    \"networkx>=3.0\",\n",
    "    \"pandas\",\n",
    "    \"tqdm\",\n",
    "    \"langchain-cohere\",\n",
    "    \"langchain-community\",\n",
    "    \"langchain\",\n",
    "    \"matplotlib\",\n",
    "    \"python-louvain\",\n",
    "    \"requests\",\n",
    "    \"httpx-sse\",\n",
    "    \"openai\",\n",
    "    \"gradio\"  # Ensure Gradio is included\n",
    "]\n",
    "\n",
    "all_packages_installed = True\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        importlib.import_module(package.replace(\"-\", \"_\"))\n",
    "        print(f\"✅ {package} is already installed\")\n",
    "    except ImportError:\n",
    "        if not install_package(package):\n",
    "            all_packages_installed = False\n",
    "\n",
    "if not all_packages_installed:\n",
    "    print(\"ERROR: Some packages failed to install.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/w2sg-arnav/anaconda3/envs/rapids-env/lib/python3.11/site-packages/cupy/_environment.py:541: UserWarning: \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  CuPy may not function correctly because multiple CuPy packages are installed\n",
      "  in your environment:\n",
      "\n",
      "    cupy, cupy-cuda12x\n",
      "\n",
      "  Follow these steps to resolve this issue:\n",
      "\n",
      "    1. For all packages listed above, run the following command to remove all\n",
      "       existing CuPy installations:\n",
      "\n",
      "         $ pip uninstall <package_name>\n",
      "\n",
      "      If you previously installed CuPy via conda, also run the following:\n",
      "\n",
      "         $ conda uninstall cupy\n",
      "\n",
      "    2. Install the appropriate CuPy package.\n",
      "       Refer to the Installation Guide for detailed instructions.\n",
      "\n",
      "         https://docs.cupy.dev/en/stable/install.html\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  warnings.warn(f'''\n",
      "[12:27:33 +0530] [INFO]: NetworkX-cuGraph is available.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 2: Import Necessary Libraries and Configuration ---\n",
    "import networkx as nx\n",
    "import nx_arangodb as nxadb\n",
    "from arango import ArangoClient\n",
    "from langchain_cohere import ChatCohere\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import gradio as gr\n",
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "# API Keys (hardcoded for submission as per your requirement)\n",
    "ARANGODB_HOST = \"https://a40b6d186a3a.arangodb.cloud:8529\"\n",
    "ARANGODB_USER = \"root\"\n",
    "ARANGODB_PASS = \"2eM5Wd4NRTrcnHQt3yfM\"\n",
    "COHERE_API_KEY = \"WcXnR3lxNWGwnoJmI2hq8CnCmPfAr8fRbFFacCsT\"\n",
    "\n",
    "# Suppress nx_arangodb warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"nx_arangodb\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to ArangoDB database: amazon_copurchase\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 3: ArangoDB Connection Function ---\n",
    "from typing import Optional\n",
    "\n",
    "def connect_to_arangodb(\n",
    "    host: str = ARANGODB_HOST,\n",
    "    username: str = ARANGODB_USER,\n",
    "    password: str = ARANGODB_PASS,\n",
    "    database: str = \"amazon_copurchase\",\n",
    ") -> Optional[object]:\n",
    "    \"\"\"Connect to ArangoDB and return database handle.\"\"\"\n",
    "    try:\n",
    "        client = ArangoClient(hosts=host)\n",
    "        sys_db = client.db(\"_system\", username=username, password=password)\n",
    "        if not sys_db.has_database(database):\n",
    "            sys_db.create_database(database)\n",
    "            print(f\"Created database: {database}\")\n",
    "        db = client.db(database, username=username, password=password)\n",
    "        print(f\"✅ Connected to ArangoDB database: {database}\")\n",
    "        return db\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error connecting to ArangoDB: {e}\")\n",
    "        return None\n",
    "\n",
    "db = connect_to_arangodb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ cugraph is not available. Using NetworkX for all graph operations.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: cuGraph Availability Check ---\n",
    "try:\n",
    "    import cugraph\n",
    "    print(\"✅ cugraph is available\")\n",
    "    use_cugraph = True\n",
    "except ImportError:\n",
    "    print(\"⚠️ cugraph is not available. Using NetworkX for all graph operations.\")\n",
    "    use_cugraph = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 5: Dataset Download and Parsing ---\n",
    "import requests\n",
    "\n",
    "def download_file(url, filename):\n",
    "    \"\"\"Download a file with progress bar\"\"\"\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size = int(r.headers.get('content-length', 0))\n",
    "        with open(filename, 'wb') as f:\n",
    "            with tqdm(total=total_size, unit='B', unit_scale=True, unit_divisor=1024, desc=filename) as pbar:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        pbar.update(len(chunk))\n",
    "    print(f\"✅ Downloaded {filename}\")\n",
    "\n",
    "def parse_amazon_copurchase(gz_file, sample_size=100000):\n",
    "    \"\"\"Parse Amazon co-purchasing network from gzipped file\"\"\"\n",
    "    print(f\"Parsing co-purchase network from {gz_file}...\")\n",
    "    edges = []\n",
    "    try:\n",
    "        with gzip.open(gz_file, 'rt', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(tqdm(f, desc=\"Reading edges\", unit=\" lines\")):\n",
    "                if not line.startswith('#'):\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 2:\n",
    "                        source, target = parts[0], parts[1]\n",
    "                        edges.append((source, target))\n",
    "                    if i >= sample_size:\n",
    "                        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {gz_file}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"✅ Parsed {len(edges)} co-purchase edges\")\n",
    "    if not edges:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.DataFrame(edges, columns=['source', 'target'])\n",
    "    df['source'] = pd.to_numeric(df['source'], errors='coerce').astype(int)\n",
    "    df['target'] = pd.to_numeric(df['target'], errors='coerce').astype(int)\n",
    "    df = df.dropna()\n",
    "    csv_filename = gz_file.replace('.gz', '.csv')\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"✅ Saved to {csv_filename}\")\n",
    "    return df\n",
    "\n",
    "# Amazon datasets\n",
    "amazon_datasets = {\n",
    "    \"amazon0302\": \"http://snap.stanford.edu/data/amazon0302.txt.gz\",\n",
    "    \"amazon0312\": \"http://snap.stanford.edu/data/amazon0312.txt.gz\",\n",
    "    \"amazon0505\": \"http://snap.stanford.edu/data/amazon0505.txt.gz\",\n",
    "    \"amazon0601\": \"http://snap.stanford.edu/data/amazon0601.txt.gz\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from amazon_data/amazon0302.txt.csv\n",
      "✅ Created amazon0302 graph with 30232 nodes and 99997 edges\n",
      "Loading from amazon_data/amazon0312.txt.csv\n",
      "✅ Created amazon0312 graph with 28648 nodes and 99997 edges\n",
      "Loading from amazon_data/amazon0505.txt.csv\n",
      "✅ Created amazon0505 graph with 22045 nodes and 99997 edges\n",
      "Loading from amazon_data/amazon0601.txt.csv\n",
      "✅ Created amazon0601 graph with 26520 nodes and 99997 edges\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 6: Load and Prepare Graphs ---\n",
    "amazon_graphs = {}\n",
    "\n",
    "def load_graphs():\n",
    "    if not os.path.exists(\"amazon_data\"):\n",
    "        os.makedirs(\"amazon_data\")\n",
    "    \n",
    "    for dataset_name, url in amazon_datasets.items():\n",
    "        filename = os.path.join(\"amazon_data\", url.split('/')[-1])\n",
    "        csv_filename = filename.replace('.gz', '.csv')\n",
    "        \n",
    "        if os.path.exists(csv_filename):\n",
    "            print(f\"Loading from {csv_filename}\")\n",
    "            df = pd.read_csv(csv_filename)\n",
    "        elif os.path.exists(filename):\n",
    "            df = parse_amazon_copurchase(filename)\n",
    "        else:\n",
    "            download_file(url, filename)\n",
    "            df = parse_amazon_copurchase(filename)\n",
    "        \n",
    "        if not df.empty:\n",
    "            G = nx.from_pandas_edgelist(df, \"source\", \"target\", create_using=nx.DiGraph())\n",
    "            amazon_graphs[dataset_name] = G\n",
    "            print(f\"✅ Created {dataset_name} graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "        else:\n",
    "            print(f\"⚠️ Failed to load data for {dataset_name}\")\n",
    "\n",
    "load_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://94df39c697add43331.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://94df39c697add43331.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Cell 7: Gradio Interface ---\n",
    "def analyze_graph(G):\n",
    "    \"\"\"Analyze a graph and return key metrics\"\"\"\n",
    "    analysis = {}\n",
    "    analysis['num_nodes'] = G.number_of_nodes()\n",
    "    analysis['num_edges'] = G.number_of_edges()\n",
    "    analysis['avg_degree'] = sum(dict(G.degree()).values()) / G.number_of_nodes()\n",
    "    analysis['density'] = nx.density(G)\n",
    "    try:\n",
    "        largest_cc = max(nx.weakly_connected_components(G), key=len)\n",
    "        analysis['largest_cc_percentage'] = (len(largest_cc) / G.number_of_nodes()) * 100\n",
    "    except:\n",
    "        analysis['largest_cc_percentage'] = \"Not computable\"\n",
    "    return analysis\n",
    "\n",
    "def create_matplotlib_visualization(graph_name):\n",
    "    if graph_name not in amazon_graphs:\n",
    "        return None\n",
    "    G = amazon_graphs[graph_name]\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos = nx.spring_layout(G, seed=42) if G.number_of_nodes() < 50 else nx.kamada_kawai_layout(G)\n",
    "    nx.draw_networkx(G, pos=pos, with_labels=True, node_color='skyblue', node_size=300, \n",
    "                    edge_color='gray', arrows=True)\n",
    "    plt.title(f\"Graph: {graph_name}\")\n",
    "    plt.axis('off')\n",
    "    file_path = os.path.join(tempfile.gettempdir(), f\"{graph_name}_plot.png\")\n",
    "    plt.savefig(file_path, format='png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return file_path\n",
    "\n",
    "def query_graph(query):\n",
    "    query = query.lower()\n",
    "    graph_name = next((name for name in amazon_graphs.keys() if name in query), None)\n",
    "    if not graph_name:\n",
    "        return \"Please specify a graph (amazon0302, amazon0312, amazon0505, or amazon0601)\"\n",
    "    \n",
    "    G = amazon_graphs[graph_name]\n",
    "    \n",
    "    if \"neighbors of\" in query or \"connected to\" in query:\n",
    "        try:\n",
    "            node_id = int(re.search(r'node (\\d+)', query).group(1))\n",
    "            neighbors = list(G.neighbors(node_id))\n",
    "            return f\"Neighbors of node {node_id} in {graph_name}: {neighbors}\"\n",
    "        except:\n",
    "            return \"Please specify a valid node number\"\n",
    "    \n",
    "    elif \"shortest path\" in query:\n",
    "        try:\n",
    "            numbers = [int(x) for x in re.findall(r'\\d+', query)]\n",
    "            source, target = numbers[0], numbers[1]\n",
    "            path = nx.shortest_path(G, source, target)\n",
    "            return f\"Shortest path from {source} to {target} in {graph_name}: {path}\"\n",
    "        except:\n",
    "            return \"Please specify valid source and target nodes\"\n",
    "    \n",
    "    return \"Query not understood\"\n",
    "\n",
    "def create_gradio_interface():\n",
    "    with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "        gr.Markdown(\"# Amazon Co-Purchase Network Analysis\")\n",
    "        \n",
    "        # Query Section\n",
    "        gr.Markdown(\"### Query the Graph\")\n",
    "        with gr.Row():\n",
    "            query_input = gr.Textbox(label=\"Enter your query\", \n",
    "                                   placeholder=\"e.g., Find neighbors of node 0 in amazon0302\")\n",
    "            query_button = gr.Button(\"Submit Query\")\n",
    "        query_output = gr.Textbox(label=\"Query Result\")\n",
    "        \n",
    "        # Visualization Section\n",
    "        gr.Markdown(\"### Visualize the Graph\")\n",
    "        with gr.Row():\n",
    "            graph_dropdown = gr.Dropdown(choices=list(amazon_graphs.keys()), \n",
    "                                       label=\"Select a graph\", \n",
    "                                       value=list(amazon_graphs.keys())[0])\n",
    "            visualize_button = gr.Button(\"Visualize Graph\")\n",
    "        visualization_output = gr.Image(label=\"Graph Visualization\", type=\"filepath\")\n",
    "        \n",
    "        # Analysis Section\n",
    "        gr.Markdown(\"### Analyze the Graph\")\n",
    "        with gr.Row():\n",
    "            analyze_dropdown = gr.Dropdown(choices=list(amazon_graphs.keys()), \n",
    "                                         label=\"Select a graph\", \n",
    "                                         value=list(amazon_graphs.keys())[0])\n",
    "            analyze_button = gr.Button(\"Analyze Graph\")\n",
    "        analysis_output = gr.Textbox(label=\"Graph Analysis\", max_lines=10)\n",
    "        \n",
    "        # Event Handlers\n",
    "        query_button.click(query_graph, inputs=query_input, outputs=query_output)\n",
    "        visualize_button.click(create_matplotlib_visualization, \n",
    "                             inputs=graph_dropdown, \n",
    "                             outputs=visualization_output)\n",
    "        analyze_button.click(lambda x: str(analyze_graph(amazon_graphs[x])), \n",
    "                           inputs=analyze_dropdown, \n",
    "                           outputs=analysis_output)\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# Launch the interface\n",
    "if amazon_graphs:\n",
    "    demo = create_gradio_interface()\n",
    "    demo.launch(share=True)\n",
    "else:\n",
    "    print(\"No graphs loaded. Please check data loading steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 7: Graph Analysis Functions ---\n",
    "def analyze_graph(G):\n",
    "    \"\"\"Analyze a graph and return key metrics\"\"\"\n",
    "    analysis = {}\n",
    "    analysis['num_nodes'] = G.number_of_nodes()\n",
    "    analysis['num_edges'] = G.number_of_edges()\n",
    "    analysis['avg_degree'] = sum(dict(G.degree()).values()) / G.number_of_nodes()\n",
    "    analysis['density'] = nx.density(G)\n",
    "    \n",
    "    try:\n",
    "        largest_cc = max(nx.weakly_connected_components(G), key=len)\n",
    "        analysis['largest_cc_percentage'] = (len(largest_cc) / G.number_of_nodes()) * 100\n",
    "        analysis['largest_cc_size'] = len(largest_cc)\n",
    "    except Exception as e:\n",
    "        analysis['largest_cc_percentage'] = \"Not computable\"\n",
    "        analysis['largest_cc_size'] = \"Not computable\"\n",
    "    \n",
    "    try:\n",
    "        degree_dict = dict(G.degree())\n",
    "        analysis['top_nodes_by_degree'] = sorted(degree_dict.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    except Exception as e:\n",
    "        analysis['top_nodes_by_degree'] = \"Not computable\"\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def detect_communities(G, max_nodes=5000):\n",
    "    \"\"\"Detect communities in the graph using Louvain, with fallback\"\"\"\n",
    "    if G.number_of_nodes() > max_nodes:\n",
    "        print(f\"Graph too large ({G.number_of_nodes()} nodes), sampling {max_nodes} nodes\")\n",
    "        seed_node = max(G.degree, key=lambda x: x[1])[0]\n",
    "        sample_nodes = set(nx.single_source_shortest_path_length(G, seed_node, cutoff=2).keys())\n",
    "        subgraph = G.subgraph(sample_nodes)\n",
    "    else:\n",
    "        subgraph = G\n",
    "    \n",
    "    undirected_G = subgraph.to_undirected()\n",
    "    \n",
    "    try:\n",
    "        import community as community_louvain\n",
    "        partition = community_louvain.best_partition(undirected_G)\n",
    "        communities = {}\n",
    "        for node, comm_id in partition.items():\n",
    "            communities.setdefault(comm_id, []).append(node)\n",
    "        sorted_communities = sorted(communities.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "        return {\n",
    "            \"algorithm\": \"louvain\",\n",
    "            \"num_communities\": len(communities),\n",
    "            \"community_sizes\": [len(comm) for _, comm in sorted_communities[:5]],\n",
    "            \"top_communities\": sorted_communities[:3]\n",
    "        }\n",
    "    except ImportError:\n",
    "        components = list(nx.connected_components(undirected_G))\n",
    "        sorted_components = sorted(components, key=len, reverse=True)\n",
    "        return {\n",
    "            \"algorithm\": \"connected_components\",\n",
    "            \"num_communities\": len(components),\n",
    "            \"community_sizes\": [len(comp) for comp in sorted_components[:5]],\n",
    "            \"top_communities\": [(i, list(comp)[:5]) for i, comp in enumerate(sorted_components[:3])]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 8: Visualization Functions ---\n",
    "def create_matplotlib_visualization(graph_name):\n",
    "    \"\"\"Create a matplotlib visualization of the graph\"\"\"\n",
    "    if graph_name not in amazon_graphs:\n",
    "        return None\n",
    "    G = amazon_graphs[graph_name]\n",
    "    \n",
    "    # Sample for large graphs\n",
    "    if G.number_of_nodes() > 100:\n",
    "        seed_node = max(G.degree, key=lambda x: x[1])[0]\n",
    "        sample_nodes = set(nx.single_source_shortest_path_length(G, seed_node, cutoff=2).keys())\n",
    "        G = G.subgraph(sample_nodes)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos = nx.spring_layout(G, seed=42) if G.number_of_nodes() < 50 else nx.kamada_kawai_layout(G)\n",
    "    nx.draw_networkx(G, pos=pos, with_labels=True, node_color='skyblue', node_size=300,\n",
    "                    edge_color='gray', arrows=True, font_size=8)\n",
    "    plt.title(f\"Graph: {graph_name} (Sampled if large)\")\n",
    "    plt.axis('off')\n",
    "    file_path = os.path.join(tempfile.gettempdir(), f\"{graph_name}_plot.png\")\n",
    "    plt.savefig(file_path, format='png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 9: Query Function ---\n",
    "def query_graph(query):\n",
    "    \"\"\"Handle graph-related queries\"\"\"\n",
    "    query = query.lower()\n",
    "    graph_name = next((name for name in amazon_graphs.keys() if name in query), None)\n",
    "    if not graph_name:\n",
    "        return \"Please specify a graph (amazon0302, amazon0312, amazon0505, or amazon0601)\"\n",
    "    \n",
    "    G = amazon_graphs[graph_name]\n",
    "    \n",
    "    if \"neighbors of\" in query or \"connected to\" in query:\n",
    "        try:\n",
    "            node_id = int(re.search(r'node (\\d+)', query).group(1))\n",
    "            if node_id not in G.nodes():\n",
    "                return f\"Node {node_id} not found in {graph_name}\"\n",
    "            neighbors = list(G.neighbors(node_id))\n",
    "            return f\"Neighbors of node {node_id} in {graph_name}: {neighbors}\"\n",
    "        except:\n",
    "            return \"Please specify a valid node number\"\n",
    "    \n",
    "    elif \"shortest path\" in query:\n",
    "        try:\n",
    "            numbers = [int(x) for x in re.findall(r'\\d+', query)]\n",
    "            source, target = numbers[0], numbers[1]\n",
    "            if source not in G.nodes() or target not in G.nodes():\n",
    "                return f\"Nodes {source} and/or {target} not found in {graph_name}\"\n",
    "            path = nx.shortest_path(G, source, target)\n",
    "            return f\"Shortest path from {source} to {target} in {graph_name}: {path}\"\n",
    "        except nx.NetworkXNoPath:\n",
    "            return f\"No path exists between nodes {source} and {target} in {graph_name}\"\n",
    "        except:\n",
    "            return \"Please specify valid source and target nodes\"\n",
    "    \n",
    "    elif \"degree of\" in query:\n",
    "        try:\n",
    "            node_id = int(re.search(r'node (\\d+)', query).group(1))\n",
    "            degree = G.degree(node_id)\n",
    "            return f\"Degree of node {node_id} in {graph_name}: {degree}\"\n",
    "        except:\n",
    "            return \"Please specify a valid node number\"\n",
    "    \n",
    "    return \"Query not understood. Try 'neighbors of node X', 'shortest path from X to Y', or 'degree of node X'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://0dd8a6e9176e63d0f2.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0dd8a6e9176e63d0f2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Cell 10: Gradio Interface ---\n",
    "def display_analysis(graph_name):\n",
    "    \"\"\"Display analysis results\"\"\"\n",
    "    if graph_name not in amazon_graphs:\n",
    "        return \"Graph not found\"\n",
    "    analysis = analyze_graph(amazon_graphs[graph_name])\n",
    "    community = detect_communities(amazon_graphs[graph_name])\n",
    "    \n",
    "    return (f\"Graph: {graph_name}\\n\"\n",
    "            f\"Nodes: {analysis['num_nodes']}\\n\"\n",
    "            f\"Edges: {analysis['num_edges']}\\n\"\n",
    "            f\"Average Degree: {analysis['avg_degree']:.2f}\\n\"\n",
    "            f\"Density: {analysis['density']:.4f}\\n\"\n",
    "            f\"Largest Component: {analysis['largest_cc_percentage']}%\\n\"\n",
    "            f\"Top 5 Nodes by Degree: {analysis['top_nodes_by_degree']}\\n\"\n",
    "            f\"Number of Communities: {community['num_communities']}\\n\"\n",
    "            f\"Top Community Sizes: {community['community_sizes']}\")\n",
    "\n",
    "def create_gradio_interface():\n",
    "    with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "        gr.Markdown(\"# Amazon Co-Purchase Network Analysis\")\n",
    "        \n",
    "        # Query Section\n",
    "        gr.Markdown(\"### Query the Graph\")\n",
    "        with gr.Row():\n",
    "            query_input = gr.Textbox(label=\"Enter your query\",\n",
    "                                   placeholder=\"e.g., Find neighbors of node 0 in amazon0302\")\n",
    "            query_button = gr.Button(\"Submit Query\")\n",
    "        query_output = gr.Textbox(label=\"Query Result\")\n",
    "        \n",
    "        # Visualization Section\n",
    "        gr.Markdown(\"### Visualize the Graph\")\n",
    "        with gr.Row():\n",
    "            graph_dropdown = gr.Dropdown(choices=list(amazon_graphs.keys()),\n",
    "                                       label=\"Select a graph\",\n",
    "                                       value=list(amazon_graphs.keys())[0])\n",
    "            visualize_button = gr.Button(\"Visualize Graph\")\n",
    "        visualization_output = gr.Image(label=\"Graph Visualization\", type=\"filepath\")\n",
    "        \n",
    "        # Analysis Section\n",
    "        gr.Markdown(\"### Analyze the Graph\")\n",
    "        with gr.Row():\n",
    "            analyze_dropdown = gr.Dropdown(choices=list(amazon_graphs.keys()),\n",
    "                                         label=\"Select a graph\",\n",
    "                                         value=list(amazon_graphs.keys())[0])\n",
    "            analyze_button = gr.Button(\"Analyze Graph\")\n",
    "        analysis_output = gr.Textbox(label=\"Graph Analysis\", max_lines=15)\n",
    "        \n",
    "        # Examples\n",
    "        gr.Markdown(\"### Example Queries\")\n",
    "        gr.Examples(\n",
    "            examples=[\n",
    "                \"Find neighbors of node 0 in amazon0302\",\n",
    "                \"Shortest path from node 0 to node 5 in amazon0312\",\n",
    "                \"Degree of node 10 in amazon0505\"\n",
    "            ],\n",
    "            inputs=query_input\n",
    "        )\n",
    "        \n",
    "        # Event Handlers\n",
    "        query_button.click(query_graph, inputs=query_input, outputs=query_output)\n",
    "        visualize_button.click(create_matplotlib_visualization,\n",
    "                             inputs=graph_dropdown,\n",
    "                             outputs=visualization_output)\n",
    "        analyze_button.click(display_analysis,\n",
    "                           inputs=analyze_dropdown,\n",
    "                           outputs=analysis_output)\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# Launch only if graphs are loaded\n",
    "if amazon_graphs:\n",
    "    demo = create_gradio_interface()\n",
    "    demo.launch(share=True)\n",
    "else:\n",
    "    print(\"No graphs loaded. Please check data loading steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 11: LangChain Integration (Optional) ---\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "cohere_llm = ChatCohere(model=\"command\", cohere_api_key=COHERE_API_KEY, temperature=0)\n",
    "\n",
    "def llm_query(query):\n",
    "    \"\"\"Use LLM to answer complex graph queries\"\"\"\n",
    "    graph_name = next((name for name in amazon_graphs.keys() if name in query.lower()), None)\n",
    "    if not graph_name:\n",
    "        return \"Please specify a graph in your query\"\n",
    "    \n",
    "    analysis = analyze_graph(amazon_graphs[graph_name])\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"Given a graph with {num_nodes} nodes, {num_edges} edges, and average degree {avg_degree}, \"\n",
    "                 \"answer this question: {query}\",\n",
    "        input_variables=[\"num_nodes\", \"num_edges\", \"avg_degree\", \"query\"]\n",
    "    )\n",
    "    chain = LLMChain(llm=cohere_llm, prompt=prompt)\n",
    "    return chain.run({\n",
    "        \"num_nodes\": analysis['num_nodes'],\n",
    "        \"num_edges\": analysis['num_edges'],\n",
    "        \"avg_degree\": analysis['avg_degree'],\n",
    "        \"query\": query\n",
    "    })\n",
    "\n",
    "# Add to Gradio interface by modifying Cell 10's query_button.click to:\n",
    "# query_button.click(lambda q: llm_query(q) if \"what\" in q.lower() or \"how\" in q.lower() else query_graph(q),\n",
    "#                    inputs=query_input, outputs=query_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Persisted amazon0302 to ArangoDB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:28:07 +0530] [INFO]: Graph 'AmazonCoPurchase_amazon0302' exists.\n",
      "[12:28:08 +0530] [INFO]: Default node type set to 'products_amazon0302'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Persisted amazon0312 to ArangoDB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:28:25 +0530] [INFO]: Graph 'AmazonCoPurchase_amazon0312' exists.\n",
      "[12:28:26 +0530] [INFO]: Default node type set to 'products_amazon0312'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Persisted amazon0505 to ArangoDB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:28:49 +0530] [INFO]: Graph 'AmazonCoPurchase_amazon0505' exists.\n",
      "[12:28:50 +0530] [INFO]: Default node type set to 'products_amazon0505'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Persisted amazon0601 to ArangoDB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:29:07 +0530] [INFO]: Graph 'AmazonCoPurchase_amazon0601' exists.\n",
      "[12:29:08 +0530] [INFO]: Default node type set to 'products_amazon0601'\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 11: ArangoDB Persistence ---\n",
    "from typing import Dict, Optional\n",
    "\n",
    "def persist_networkx_graph_to_arangodb(db, graph_name: str, G: nx.Graph, prefix: str = \"AmazonCoPurchase\"):\n",
    "    \"\"\"Persist a NetworkX graph to ArangoDB\"\"\"\n",
    "    if not db:\n",
    "        print(\"⚠️ No database connection provided.\")\n",
    "        return None\n",
    "    \n",
    "    arangodb_graph_name = f\"{prefix}_{graph_name}\"\n",
    "    nodes_collection_name = f\"products_{graph_name}\"\n",
    "    edges_collection_name = f\"copurchases_{graph_name}\"\n",
    "    \n",
    "    try:\n",
    "        if db.has_graph(arangodb_graph_name):\n",
    "            graph = db.graph(arangodb_graph_name)\n",
    "            nodes = graph.vertex_collection(nodes_collection_name)\n",
    "            edges = graph.edge_collection(edges_collection_name)\n",
    "        else:\n",
    "            graph = db.create_graph(arangodb_graph_name)\n",
    "            nodes = graph.create_vertex_collection(nodes_collection_name)\n",
    "            edges = graph.create_edge_definition(\n",
    "                edge_collection=edges_collection_name,\n",
    "                from_vertex_collections=[nodes_collection_name],\n",
    "                to_vertex_collections=[nodes_collection_name],\n",
    "            )\n",
    "        \n",
    "        # Batch process nodes\n",
    "        node_batch = [{'_key': str(node)} for node in G.nodes()]\n",
    "        nodes.import_bulk(node_batch, on_duplicate=\"replace\")\n",
    "        \n",
    "        # Batch process edges\n",
    "        edge_batch = [\n",
    "            {\"_from\": f\"{nodes_collection_name}/{source}\", \n",
    "             \"_to\": f\"{nodes_collection_name}/{target}\"}\n",
    "            for source, target in G.edges()\n",
    "        ]\n",
    "        edges.import_bulk(edge_batch, on_duplicate=\"replace\")\n",
    "        \n",
    "        print(f\"✅ Persisted {graph_name} to ArangoDB\")\n",
    "        return nxadb.Graph(name=arangodb_graph_name, db=db)\n",
    "    except Exception as e:\n",
    "        print(f\"Error persisting graph: {e}\")\n",
    "        return None\n",
    "\n",
    "def persist_all_graphs():\n",
    "    \"\"\"Persist all graphs to ArangoDB\"\"\"\n",
    "    if not db:\n",
    "        return {}\n",
    "    \n",
    "    adb_graphs = {}\n",
    "    for graph_name, G in amazon_graphs.items():\n",
    "        adb_graph = persist_networkx_graph_to_arangodb(db, graph_name, G)\n",
    "        if adb_graph:\n",
    "            adb_graphs[graph_name] = adb_graph\n",
    "    return adb_graphs\n",
    "\n",
    "# Persist graphs\n",
    "adb_graphs = persist_all_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 12: LangChain Setup and Agent ---\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_community.graphs import ArangoGraph\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage  # Import message types\n",
    "\n",
    "cohere_llm = ChatCohere(model=\"command\", cohere_api_key=COHERE_API_KEY, temperature=0)\n",
    "arango_graph = ArangoGraph(db=db) if db else None\n",
    "\n",
    "@tool\n",
    "def arango_query(query: str):\n",
    "    \"\"\"Execute AQL queries via LangChain\"\"\"\n",
    "    if not arango_graph:\n",
    "        return \"ArangoDB not available\"\n",
    "    chain = ArangoGraphQAChain.from_llm(llm=cohere_llm, graph=arango_graph, verbose=True)\n",
    "    return str(chain.invoke({\"query\": query})[\"result\"])\n",
    "\n",
    "@tool\n",
    "def networkx_query(query: str):\n",
    "    \"\"\"Execute NetworkX queries\"\"\"\n",
    "    graph_name = next((name for name in amazon_graphs.keys() if name in query.lower()), None)\n",
    "    if not graph_name:\n",
    "        return \"Please specify a graph name\"\n",
    "    \n",
    "    G = amazon_graphs[graph_name]\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"Using a NetworkX DiGraph with {num_nodes} nodes and {num_edges} edges, \"\n",
    "                 \"write Python code to answer: {query}. Set FINAL_RESULT to the answer.\",\n",
    "        input_variables=[\"num_nodes\", \"num_edges\", \"query\"]\n",
    "    )\n",
    "    chain = LLMChain(llm=cohere_llm, prompt=prompt)\n",
    "    code = chain.invoke({\"num_nodes\": G.number_of_nodes(), \"num_edges\": G.number_of_edges(), \"query\": query})[\"text\"]\n",
    "    \n",
    "    try:\n",
    "        local_vars = {}\n",
    "        exec(code, {\"nx\": nx, \"nx_graph\": G}, local_vars)\n",
    "        return str(local_vars.get(\"FINAL_RESULT\", \"No result computed\"))\n",
    "    except Exception as e:\n",
    "        return f\"Error executing code: {e}\"\n",
    "\n",
    "tools = [arango_query, networkx_query]\n",
    "\n",
    "# Corrected prompt with explicit instructions and handling of agent_scratchpad\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a graph analysis assistant. Use the following tools to answer queries about Amazon co-purchase networks:\n",
    "\n",
    "Available tools: {tools}\n",
    "Tool names: {tool_names}\n",
    "\n",
    "Answer in a step-by-step format showing your reasoning. Use the tools provided to compute answers. For example:\n",
    "\n",
    "Query: \"What are the neighbors of node 0 in amazon0302?\"\n",
    "Thought: I need to find the neighbors of a specific node in a NetworkX graph. The networkx_query tool is appropriate.\n",
    "Action: networkx_query\n",
    "Action Input: \"What are the neighbors of node 0 in amazon0302?\"\n",
    "\n",
    "The agent_scratchpad will contain the history of your reasoning and actions as a list of messages. Use it to track your progress.\n",
    "\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),  # This expects a list of messages\n",
    "    (\"human\", \"{input}\"),  # Changed \"user\" to \"human\" for consistency with LangChain\n",
    "])\n",
    "\n",
    "agent = create_react_agent(cohere_llm, tools, prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "def enhanced_query(query):\n",
    "    \"\"\"Enhanced query function using LangChain agent\"\"\"\n",
    "    # Initialize agent_scratchpad as an empty list of messages\n",
    "    try:\n",
    "        result = agent_executor.invoke({\n",
    "            \"input\": query,\n",
    "            \"agent_scratchpad\": []  # Start with an empty list of messages\n",
    "        })\n",
    "        return result[\"output\"]\n",
    "    except Exception as e:\n",
    "        return f\"Error processing query: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing amazon0302...\n",
      "Graph too large (30232 nodes), sampling 5000 nodes\n",
      "Analyzing amazon0312...\n",
      "Graph too large (28648 nodes), sampling 5000 nodes\n",
      "Analyzing amazon0505...\n",
      "Graph too large (22045 nodes), sampling 5000 nodes\n",
      "Analyzing amazon0601...\n",
      "Graph too large (26520 nodes), sampling 5000 nodes\n",
      "✅ Analysis complete\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 13: Main Analysis and Storage ---\n",
    "graph_analyses = {}\n",
    "community_analyses = {}\n",
    "\n",
    "def run_analysis():\n",
    "    \"\"\"Run analysis on all graphs\"\"\"\n",
    "    for graph_name, G in amazon_graphs.items():\n",
    "        print(f\"Analyzing {graph_name}...\")\n",
    "        graph_analyses[graph_name] = analyze_graph(G)\n",
    "        community_analyses[graph_name] = detect_communities(G)\n",
    "\n",
    "if amazon_graphs:\n",
    "    run_analysis()\n",
    "    print(\"✅ Analysis complete\")\n",
    "else:\n",
    "    print(\"⚠️ No graphs to analyze\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://1b4cffebc047a8e320.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1b4cffebc047a8e320.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Cell 14: Enhanced Gradio Interface ---\n",
    "def create_enhanced_gradio_interface():\n",
    "    with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "        gr.Markdown(\"# Amazon Co-Purchase Network Analysis\")\n",
    "        \n",
    "        # Query Section\n",
    "        gr.Markdown(\"### Query the Graph\")\n",
    "        with gr.Row():\n",
    "            query_input = gr.Textbox(label=\"Enter your query\",\n",
    "                                   placeholder=\"e.g., What are the neighbors of node 0 in amazon0302?\")\n",
    "            query_button = gr.Button(\"Submit Query\")\n",
    "        query_output = gr.Textbox(label=\"Query Result\")\n",
    "        \n",
    "        # Visualization Section\n",
    "        gr.Markdown(\"### Visualize the Graph\")\n",
    "        with gr.Row():\n",
    "            graph_dropdown = gr.Dropdown(choices=list(amazon_graphs.keys()),\n",
    "                                       label=\"Select a graph\",\n",
    "                                       value=list(amazon_graphs.keys())[0])\n",
    "            visualize_button = gr.Button(\"Visualize Graph\")\n",
    "        visualization_output = gr.Image(label=\"Graph Visualization\", type=\"filepath\")\n",
    "        \n",
    "        # Analysis Section\n",
    "        gr.Markdown(\"### Analyze the Graph\")\n",
    "        with gr.Row():\n",
    "            analyze_dropdown = gr.Dropdown(choices=list(amazon_graphs.keys()),\n",
    "                                         label=\"Select a graph\",\n",
    "                                         value=list(amazon_graphs.keys())[0])\n",
    "            analyze_button = gr.Button(\"Analyze Graph\")\n",
    "        analysis_output = gr.Textbox(label=\"Graph Analysis\", max_lines=15)\n",
    "        \n",
    "        # Examples\n",
    "        gr.Markdown(\"### Example Queries\")\n",
    "        gr.Examples(\n",
    "            examples=[\n",
    "                \"What are the neighbors of node 0 in amazon0302?\",\n",
    "                \"Find the shortest path from node 0 to node 5 in amazon0312\",\n",
    "                \"What is the degree distribution in amazon0505?\",\n",
    "                \"How many communities are in amazon0601?\"\n",
    "            ],\n",
    "            inputs=query_input\n",
    "        )\n",
    "        \n",
    "        # Event Handlers\n",
    "        query_button.click(enhanced_query, inputs=query_input, outputs=query_output)\n",
    "        visualize_button.click(create_matplotlib_visualization,\n",
    "                             inputs=graph_dropdown,\n",
    "                             outputs=visualization_output)\n",
    "        analyze_button.click(display_analysis,\n",
    "                           inputs=analyze_dropdown,\n",
    "                           outputs=analysis_output)\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# Launch enhanced interface\n",
    "if amazon_graphs:\n",
    "    demo = create_enhanced_gradio_interface()\n",
    "    demo.launch(share=True)\n",
    "else:\n",
    "    print(\"No graphs loaded. Please check data loading steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree distribution plot saved for amazon0302: /tmp/amazon0302_degree_dist.png\n",
      "Degree distribution plot saved for amazon0312: /tmp/amazon0312_degree_dist.png\n",
      "Degree distribution plot saved for amazon0505: /tmp/amazon0505_degree_dist.png\n",
      "Degree distribution plot saved for amazon0601: /tmp/amazon0601_degree_dist.png\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 15: Visualization of Analysis Results ---\n",
    "def plot_degree_distribution(graph_name):\n",
    "    \"\"\"Plot degree distribution for a graph\"\"\"\n",
    "    if graph_name not in amazon_graphs:\n",
    "        return None\n",
    "    \n",
    "    G = amazon_graphs[graph_name]\n",
    "    degrees = [d for n, d in G.degree()]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(degrees, bins=50, log=True)\n",
    "    plt.title(f\"Degree Distribution - {graph_name}\")\n",
    "    plt.xlabel(\"Degree\")\n",
    "    plt.ylabel(\"Frequency (log scale)\")\n",
    "    file_path = os.path.join(tempfile.gettempdir(), f\"{graph_name}_degree_dist.png\")\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    "    return file_path\n",
    "\n",
    "# Example usage\n",
    "if amazon_graphs:\n",
    "    for graph_name in amazon_graphs.keys():\n",
    "        dist_plot = plot_degree_distribution(graph_name)\n",
    "        if dist_plot:\n",
    "            print(f\"Degree distribution plot saved for {graph_name}: {dist_plot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing metadata from amazon_data/metadata.json.gz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata: 9430088 lines [01:13, 128991.42 lines/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 16: Metadata Integration ---\n",
    "def parse_amazon_metadata(gz_file, sample_size=10000):\n",
    "    \"\"\"Parse Amazon metadata from gzipped JSON file\"\"\"\n",
    "    print(f\"Parsing metadata from {gz_file}...\")\n",
    "    products = []\n",
    "    try:\n",
    "        with gzip.open(gz_file, 'rt', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(tqdm(f, desc=\"Reading metadata\", unit=\" lines\")):\n",
    "                if line.strip():\n",
    "                    try:\n",
    "                        product = json.loads(line)\n",
    "                        products.append(product)\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "                if i >= sample_size:\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing metadata: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.DataFrame(products)\n",
    "    if 'asin' in df.columns:\n",
    "        df['asin'] = df['asin'].astype(str)\n",
    "        csv_filename = gz_file.replace('.gz', '.csv')\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        print(f\"✅ Saved metadata to {csv_filename}\")\n",
    "    return df\n",
    "\n",
    "def add_metadata_to_graphs():\n",
    "    \"\"\"Add metadata to existing graphs\"\"\"\n",
    "    metadata_url = \"http://snap.stanford.edu/data/amazon/productGraph/metadata.json.gz\"\n",
    "    filename = os.path.join(\"amazon_data\", \"metadata.json.gz\")\n",
    "    csv_filename = filename.replace('.gz', '.csv')\n",
    "    \n",
    "    if os.path.exists(csv_filename):\n",
    "        metadata_df = pd.read_csv(csv_filename)\n",
    "    elif os.path.exists(filename):\n",
    "        metadata_df = parse_amazon_metadata(filename)\n",
    "    else:\n",
    "        download_file(metadata_url, filename)\n",
    "        metadata_df = parse_amazon_metadata(filename)\n",
    "    \n",
    "    if not metadata_df.empty and 'asin' in metadata_df.columns:\n",
    "        for graph_name, G in amazon_graphs.items():\n",
    "            print(f\"Adding metadata to {graph_name}...\")\n",
    "            for node in tqdm(G.nodes(), desc=\"Updating nodes\"):\n",
    "                node_str = str(node)\n",
    "                metadata = metadata_df[metadata_df['asin'] == node_str]\n",
    "                if not metadata.empty:\n",
    "                    for col in metadata.columns:\n",
    "                        if col != 'asin':\n",
    "                            value = metadata[col].iloc[0]\n",
    "                            if pd.notna(value):\n",
    "                                G.nodes[node][col] = value\n",
    "            # Re-persist with metadata\n",
    "            if db:\n",
    "                persist_networkx_graph_to_arangodb(db, graph_name, G)\n",
    "\n",
    "if amazon_graphs:\n",
    "    add_metadata_to_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing metadata from amazon_data/metadata.json.gz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata: 9430088 lines [01:12, 129240.77 lines/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 16: Metadata Integration ---\n",
    "def parse_amazon_metadata(gz_file, sample_size=10000):\n",
    "    \"\"\"Parse Amazon metadata from gzipped JSON file\"\"\"\n",
    "    print(f\"Parsing metadata from {gz_file}...\")\n",
    "    products = []\n",
    "    try:\n",
    "        with gzip.open(gz_file, 'rt', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(tqdm(f, desc=\"Reading metadata\", unit=\" lines\")):\n",
    "                if line.strip():\n",
    "                    try:\n",
    "                        product = json.loads(line)\n",
    "                        products.append(product)\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "                if i >= sample_size:\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing metadata: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.DataFrame(products)\n",
    "    if 'asin' in df.columns:\n",
    "        df['asin'] = df['asin'].astype(str)\n",
    "        csv_filename = gz_file.replace('.gz', '.csv')\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        print(f\"✅ Saved metadata to {csv_filename}\")\n",
    "    return df\n",
    "\n",
    "def add_metadata_to_graphs():\n",
    "    \"\"\"Add metadata to existing graphs\"\"\"\n",
    "    metadata_url = \"http://snap.stanford.edu/data/amazon/productGraph/metadata.json.gz\"\n",
    "    filename = os.path.join(\"amazon_data\", \"metadata.json.gz\")\n",
    "    csv_filename = filename.replace('.gz', '.csv')\n",
    "    \n",
    "    if os.path.exists(csv_filename):\n",
    "        metadata_df = pd.read_csv(csv_filename)\n",
    "    elif os.path.exists(filename):\n",
    "        metadata_df = parse_amazon_metadata(filename)\n",
    "    else:\n",
    "        download_file(metadata_url, filename)\n",
    "        metadata_df = parse_amazon_metadata(filename)\n",
    "    \n",
    "    if not metadata_df.empty and 'asin' in metadata_df.columns:\n",
    "        for graph_name, G in amazon_graphs.items():\n",
    "            print(f\"Adding metadata to {graph_name}...\")\n",
    "            for node in tqdm(G.nodes(), desc=\"Updating nodes\"):\n",
    "                node_str = str(node)\n",
    "                metadata = metadata_df[metadata_df['asin'] == node_str]\n",
    "                if not metadata.empty:\n",
    "                    for col in metadata.columns:\n",
    "                        if col != 'asin':\n",
    "                            value = metadata[col].iloc[0]\n",
    "                            if pd.notna(value):\n",
    "                                G.nodes[node][col] = value\n",
    "            # Re-persist with metadata\n",
    "            if db:\n",
    "                persist_networkx_graph_to_arangodb(db, graph_name, G)\n",
    "\n",
    "if amazon_graphs:\n",
    "    add_metadata_to_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community distribution plot saved for amazon0302: /tmp/amazon0302_comm_dist.png\n",
      "Community distribution plot saved for amazon0312: /tmp/amazon0312_comm_dist.png\n",
      "Community distribution plot saved for amazon0505: /tmp/amazon0505_comm_dist.png\n",
      "Community distribution plot saved for amazon0601: /tmp/amazon0601_comm_dist.png\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 17: Community Visualization ---\n",
    "def plot_community_distribution(graph_name):\n",
    "    \"\"\"Visualize community size distribution\"\"\"\n",
    "    if graph_name not in community_analyses:\n",
    "        return None\n",
    "    \n",
    "    comm_data = community_analyses[graph_name]\n",
    "    sizes = comm_data['community_sizes']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(sizes)), sizes)\n",
    "    plt.title(f\"Community Size Distribution - {graph_name}\")\n",
    "    plt.xlabel(\"Community Index (Top 5)\")\n",
    "    plt.ylabel(\"Size\")\n",
    "    file_path = os.path.join(tempfile.gettempdir(), f\"{graph_name}_comm_dist.png\")\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    "    return file_path\n",
    "\n",
    "# Example usage\n",
    "if community_analyses:\n",
    "    for graph_name in community_analyses.keys():\n",
    "        comm_plot = plot_community_distribution(graph_name)\n",
    "        if comm_plot:\n",
    "            print(f\"Community distribution plot saved for {graph_name}: {comm_plot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exported analysis results to amazon_graph_analysis.json\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 18: Export Results ---\n",
    "import json\n",
    "\n",
    "def export_analysis_results():\n",
    "    \"\"\"Export analysis results to JSON\"\"\"\n",
    "    results = {\n",
    "        \"graph_analyses\": {name: analysis for name, analysis in graph_analyses.items()},  # No vars() needed\n",
    "        \"community_analyses\": {name: comm for name, comm in community_analyses.items()}   # Already a dict\n",
    "    }\n",
    "    \n",
    "    output_file = \"amazon_graph_analysis.json\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"✅ Exported analysis results to {output_file}\")\n",
    "\n",
    "if graph_analyses and community_analyses:\n",
    "    export_analysis_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching on port 7864...\n",
      "* Running on local URL:  http://0.0.0.0:7864\n",
      "* Running on public URL: https://448c0e3b00ee03c2e5.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://448c0e3b00ee03c2e5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Graph too large (30232 nodes), sampling 5000 nodes\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 19: Final Gradio Interface with Enhanced Aesthetics and Robust Port Handling ---\n",
    "import gradio as gr\n",
    "from gradio.themes import Soft\n",
    "import matplotlib.pyplot as plt\n",
    "import socket\n",
    "\n",
    "# Custom theme with a modern, sleek look\n",
    "custom_theme = Soft(\n",
    "    primary_hue=\"indigo\",\n",
    "    secondary_hue=\"purple\",\n",
    "    neutral_hue=\"gray\",\n",
    "    text_size=\"lg\",\n",
    "    radius_size=\"md\",\n",
    "    spacing_size=\"lg\",\n",
    ").set(\n",
    "    body_background_fill=\"#f5f7fa\",\n",
    "    body_background_fill_dark=\"#1a1b26\",\n",
    "    button_primary_background_fill=\"#4f46e5\",\n",
    "    button_primary_text_color=\"#ffffff\",\n",
    "    button_secondary_background_fill=\"#9333ea\",\n",
    "    block_background_fill=\"#ffffff\",\n",
    "    block_border_color=\"#e0e7ff\",\n",
    "    block_shadow=\"0 4px 6px rgba(0, 0, 0, 0.1)\",\n",
    ")\n",
    "\n",
    "def find_free_port(start_port=7860, max_attempts=10):\n",
    "    \"\"\"Find an available port starting from start_port.\"\"\"\n",
    "    port = start_port\n",
    "    for _ in range(max_attempts):\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            try:\n",
    "                s.bind((\"0.0.0.0\", port))\n",
    "                return port\n",
    "            except OSError:\n",
    "                port += 1\n",
    "    raise OSError(f\"No free ports found in range {start_port}-{start_port + max_attempts - 1}\")\n",
    "\n",
    "def create_final_gradio_interface():\n",
    "    with gr.Blocks(\n",
    "        title=\"Amazon Co-Purchase Network Explorer\",\n",
    "        theme=custom_theme,\n",
    "        css=\"\"\"\n",
    "            .gradio-container { max-width: 1200px; margin: auto; }\n",
    "            h1 { font-family: 'Arial', sans-serif; font-weight: bold; color: #4f46e5; text-align: center; }\n",
    "            .section-header { color: #9333ea; font-size: 1.5em; margin-bottom: 10px; }\n",
    "            .example-box { background-color: #eef2ff; padding: 10px; border-radius: 8px; }\n",
    "            .output-box { border: 2px solid #e0e7ff; border-radius: 8px; padding: 10px; }\n",
    "        \"\"\"\n",
    "    ) as demo:\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # Amazon Co-Purchase Network Explorer\n",
    "            Dive into the world of Amazon product relationships with cutting-edge graph analysis!\n",
    "            \"\"\",\n",
    "            elem_classes=[\"header\"]\n",
    "        )\n",
    "\n",
    "        with gr.Tabs():\n",
    "            with gr.Tab(\"Query Explorer\", elem_id=\"query-tab\"):\n",
    "                gr.Markdown(\"### Unleash Your Questions\", elem_classes=[\"section-header\"])\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=3):\n",
    "                        query_input = gr.Textbox(\n",
    "                            label=\"Ask Away\",\n",
    "                            placeholder=\"Try: 'What are the neighbors of node 0 in amazon0302?'\",\n",
    "                            lines=2,\n",
    "                            show_label=True,\n",
    "                            elem_classes=[\"input-box\"]\n",
    "                        )\n",
    "                    with gr.Column(scale=1):\n",
    "                        query_button = gr.Button(\"Explore\", variant=\"primary\")\n",
    "                query_output = gr.Textbox(\n",
    "                    label=\"Discovery Zone\",\n",
    "                    lines=5,\n",
    "                    show_copy_button=True,\n",
    "                    elem_classes=[\"output-box\"]\n",
    "                )\n",
    "                gr.Markdown(\"#### Cool Query Ideas\", elem_classes=[\"section-header\"])\n",
    "                with gr.Group(elem_classes=[\"example-box\"]):\n",
    "                    gr.Examples(\n",
    "                        examples=[\n",
    "                            \"What are the neighbors of node 0 in amazon0302?\",\n",
    "                            \"Find the shortest path from node 0 to node 5 in amazon0312\",\n",
    "                            \"What is the degree distribution in amazon0505?\",\n",
    "                            \"How many communities are in amazon0601?\",\n",
    "                            \"What products are frequently co-purchased with node 10 in amazon0302?\"\n",
    "                        ],\n",
    "                        inputs=query_input\n",
    "                    )\n",
    "\n",
    "            with gr.Tab(\"Visual Insights\", elem_id=\"viz-tab\"):\n",
    "                gr.Markdown(\"### See the Network in Action\", elem_classes=[\"section-header\"])\n",
    "                with gr.Row():\n",
    "                    graph_dropdown = gr.Dropdown(\n",
    "                        choices=list(amazon_graphs.keys()),\n",
    "                        label=\"Pick Your Graph\",\n",
    "                        value=list(amazon_graphs.keys())[0],\n",
    "                        elem_classes=[\"input-box\"]\n",
    "                    )\n",
    "                    viz_type = gr.Radio(\n",
    "                        [\"Graph\", \"Degree Distribution\", \"Community Distribution\"],\n",
    "                        label=\"Visualization Style\",\n",
    "                        value=\"Graph\",\n",
    "                        elem_classes=[\"input-box\"]\n",
    "                    )\n",
    "                    visualize_button = gr.Button(\"Reveal\", variant=\"secondary\")\n",
    "                visualization_output = gr.Image(\n",
    "                    label=\"Network Vision\",\n",
    "                    type=\"filepath\",\n",
    "                    elem_classes=[\"output-box\"],\n",
    "                    height=500\n",
    "                )\n",
    "                gr.Markdown(\n",
    "                    \"*Tip: Switch between styles to uncover different perspectives!*\",\n",
    "                    elem_classes=[\"tip\"]\n",
    "                )\n",
    "\n",
    "            with gr.Tab(\"Deep Analysis\", elem_id=\"analysis-tab\"):\n",
    "                gr.Markdown(\"### Crunch the Numbers\", elem_classes=[\"section-header\"])\n",
    "                with gr.Row():\n",
    "                    analyze_dropdown = gr.Dropdown(\n",
    "                        choices=list(amazon_graphs.keys()),\n",
    "                        label=\"Choose Graph to Analyze\",\n",
    "                        value=list(amazon_graphs.keys())[0],\n",
    "                        elem_classes=[\"input-box\"]\n",
    "                    )\n",
    "                    analyze_button = gr.Button(\"Analyze\", variant=\"primary\")\n",
    "                analysis_output = gr.Textbox(\n",
    "                    label=\"Insights Unveiled\",\n",
    "                    lines=10,\n",
    "                    show_copy_button=True,\n",
    "                    elem_classes=[\"output-box\"]\n",
    "                )\n",
    "                gr.Markdown(\n",
    "                    \"*Dive into node counts, degrees, and community structures!*\",\n",
    "                    elem_classes=[\"tip\"]\n",
    "                )\n",
    "\n",
    "        # Event Handlers\n",
    "        def viz_selector(graph_name, viz_type):\n",
    "            if viz_type == \"Graph\":\n",
    "                return create_matplotlib_visualization(graph_name)\n",
    "            elif viz_type == \"Degree Distribution\":\n",
    "                return plot_degree_distribution(graph_name)\n",
    "            else:\n",
    "                return plot_community_distribution(graph_name)\n",
    "\n",
    "        query_button.click(\n",
    "            enhanced_query,\n",
    "            inputs=query_input,\n",
    "            outputs=query_output\n",
    "        )\n",
    "        visualize_button.click(\n",
    "            viz_selector,\n",
    "            inputs=[graph_dropdown, viz_type],\n",
    "            outputs=visualization_output\n",
    "        )\n",
    "        analyze_button.click(\n",
    "            display_analysis,\n",
    "            inputs=analyze_dropdown,\n",
    "            outputs=analysis_output\n",
    "        )\n",
    "\n",
    "    return demo\n",
    "\n",
    "# Launch the masterpiece with dynamic port selection\n",
    "if amazon_graphs:\n",
    "    try:\n",
    "        demo = create_final_gradio_interface()\n",
    "        port = find_free_port(start_port=7860)  # Start at 7860, increment if needed\n",
    "        print(f\"Launching on port {port}...\")\n",
    "        demo.launch(share=True, server_name=\"0.0.0.0\", server_port=port)\n",
    "    except OSError as e:\n",
    "        print(f\"Failed to launch Gradio: {e}\")\n",
    "        print(\"Please free up ports or try a different range. Run 'lsof -i :7860' to check port usage.\")\n",
    "else:\n",
    "    print(\"No graphs loaded. Please check data loading steps.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
